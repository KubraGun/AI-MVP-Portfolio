import streamlit as st
from langchain_community.chat_models import ChatOllama
from langchain.schema import SystemMessage, HumanMessage
from langchain.memory import ConversationBufferMemory

# streaming callbacks
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler # terminale yazmak
from langchain.callbacks.base import BaseCallbackHandler # streamlit ile Ã§alÄ±ÅŸmak iÃ§in Ã¶zel handler. oluÅŸturacaÄŸÄ±mÄ±z class Ä±n base class Ä± olacak
from typing import Any

# streamlit iÃ§in Ã¶zel streaming callback tanÄ±mÄ±
class StreamHandler(BaseCallbackHandler):
    def __init__(self, placeholder):
        self.placeholder = placeholder # streamlit iÃ§erisindeki mesaj kutusu
        self.final_text = ""
    
    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        self.final_text += token # token larÄ± birleÅŸtir
        self.placeholder.markdown(self.final_text + " ") # canlÄ± oalrak yaz.

st.set_page_config(page_title="AkÄ±llÄ± Turist Rehber (CanlÄ±)", page_icon="ğŸŒ")
st.title("ğŸŒ AkÄ±llÄ± Turist Rehberi (Streaming Mode)")
st.markdown("TÃ¼rkiye'ni dÃ¶rt bir yanÄ±ndaki turistik yerler hakkÄ±nda bilgi almak iÃ§in sorular sorabilirsiniz.")

if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(return_messages=True) # Mesaj geÃ§miÅŸi

user_input = st.chat_input("Bir ÅŸehir, mekan, yemek ya da aktivite sorabilirsiniz...")

for msg in st.session_state.memory.chat_memory.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("ğŸ‘©ğŸ¼ KullanÄ±cÄ±"):
            st.markdown(msg.content)
    else: # mesajÄ± ai gÃ¶ndermiÅŸse
        with st.chat_message("ğŸ¤– AkÄ±llÄ± Rehber"):
            st.markdown(msg.content)

if user_input: 
    # eÄŸer user input varsa yeni gelen kullanÄ±cÄ± mesajÄ±nÄ± ilk olarak memory ye ekleriz
    st.session_state.memory.chat_memory.add_user_message(user_input)
    with st.chat_message("ğŸ‘©ğŸ¼ KullanÄ±cÄ±"):
        st.markdown(user_input)

    with st.chat_message("ğŸ¤– AkÄ±llÄ± Rehber"):
        response_placeholder = st.empty() # streamlit'te geÃ§ici mesaj kutusu
        stream_handler = StreamHandler(response_placeholder)

        llm = ChatOllama(model="llama3.2:3b", streaming = True, callbacks=[stream_handler]) # token geldikÃ§e ekrana yazÄ±dÄ±rlÄ±r vaziyette

    
        # tÃ¼m konuÅŸmayÄ± mpdele verecek ÅŸekilde mesajlarÄ± oluÅŸturur â†’ systemmesage+memory+human
        messages = [
            SystemMessage(content="Sen akÄ±llÄ± turizm ve turist rehberisin."
                        "KullanÄ±cÄ±lara TÃ¼rkiyedeki ÅŸehirler, tarihi yerler, yÃ¶resel yemekler, ulaÅŸÄ±m ve tatil Ã¶nerileri hakkÄ±nda gÃ¼zel bilgiler ver")
        ] + st.session_state.memory.load_memory_variables([])["history"] + [
            HumanMessage(content=user_input)
        ]

        # modelden yanÄ±t al
        response = llm(messages)

        # yanÄ±tÄ± hafÄ±zaya kaydet
        st.session_state.memory.chat_memory.add_ai_message(response.content)
